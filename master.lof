\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Image-based visual servoing (IBVS) structure\relax }}{2}{figure.caption.7}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Frames of interest: body frame, gimbal-1 frame, and gimbal frame\relax }}{5}{figure.caption.8}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Camera frame and visual aid for projective camera model\relax }}{7}{figure.caption.9}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Prototype hardware to test the gimbal control algorithm\relax }}{9}{figure.caption.10}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Hardware demonstration. The gimbal control algorithm is keeping the target object at the center of the camera field of view.\relax }}{10}{figure.caption.11}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Elevation and cross-elevation axis\relax }}{11}{figure.caption.12}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Angular velocity commanding gimbal controller block diagram\relax }}{16}{figure.caption.13}
\contentsline {figure}{\numberline {2.7}{\ignorespaces An MRAC closed-loop block diagram\relax }}{17}{figure.caption.14}
\contentsline {figure}{\numberline {2.8}{\ignorespaces The simulation result for the adaptive depth gimbal control. The system output $u$ and $w$ are converging to the reference model output $u_{ref}$ and $w_{ref}$.\relax }}{21}{figure.caption.15}
\contentsline {figure}{\numberline {2.9}{\ignorespaces Angular velocity commands of the adaptive depth gimbal controller. Note that only two commands are used, since it is a pan-tilt gimbal. The depth $z$ estimate using MRAC.\relax }}{21}{figure.caption.16}
\contentsline {figure}{\numberline {2.10}{\ignorespaces Multirotor simulation with camera view. The gimbal pointing objective is well achieved.\relax }}{22}{figure.caption.17}
\contentsline {figure}{\numberline {2.11}{\ignorespaces Uncertain parameter estimation, gimbal angular velocity commands from the controller, and where target lies in the image.\relax }}{23}{figure.caption.18}
\contentsline {figure}{\numberline {2.12}{\ignorespaces A custom pan-tilt camera gimbal\relax }}{24}{figure.caption.19}
\contentsline {figure}{\numberline {2.13}{\ignorespaces A custom pan-tilt camera gimbal\relax }}{24}{figure.caption.20}
\contentsline {figure}{\numberline {2.14}{\ignorespaces Custom gimbal block diagram\relax }}{24}{figure.caption.21}
\contentsline {figure}{\numberline {2.15}{\ignorespaces Adaptive depth gimbal control result on the custom-built hardware.\relax }}{25}{figure.caption.22}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces System Architecture. The R-RANSAC tracker produces a set of target ID numbers and corresponding pixel locations. The visual-servoing controller outputs the desired position, heading, and yaw rate based on the pixel location of the requested target.\relax }}{27}{figure.caption.24}
\contentsline {figure}{\numberline {3.2}{\ignorespaces This figure illustrates the detection framework used to generate measurements used by R-RANSAC. The KLT tracker creates point correspondences between frames which are used to calculate a homography. The difference image detects motion in the frame and creates position measurements of potential targets.\relax }}{29}{figure.caption.25}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Side view of the multirotor.\relax }}{31}{figure.caption.26}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Camera view at various events\relax }}{34}{figure.caption.27}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Tracks movement in the normalized image plane. Each event (1)-(4) corresponds to camera view in \ref {camera1}-\ref {camera4} respectively. Until the command to follow ID 65, the multirotor keeps the track ID 51 from leaving the camera view.\relax }}{35}{figure.caption.28}
\contentsline {figure}{\numberline {3.6}{\ignorespaces The movement of track ID 65 in the normalized image plane. Each event (3)-(5) corresponds to camera view in \ref {camera3}-\ref {camera5} respectively. The controller keeps the track ID 65 in the camera field of view after receiving the command to do so from the human operator.\relax }}{35}{figure.caption.29}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Multirotor GPS footage and heading corresponding to camera view in \ref {camera1}-\ref {camera5} respectively.\relax }}{36}{figure.caption.30}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Non-flat-earth model example. The unit optical axis vector $\mathaccentV {hat}05E{m}$ and the unit line of sight vector $\mathaccentV {hat}05E{\ell }$ are key components of the controller presented in this chapter.\relax }}{37}{figure.caption.31}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Graphical overview of the problem\relax }}{38}{figure.caption.32}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Projection onto the null space of the optical axis unit vector\relax }}{39}{figure.caption.33}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Simple UAV dynamics visual servoing Simulink simulation. The blue square is flying UAV at constant altitude and the red square is a target on the ground moving at $5m/s$. The initial UAV and target positions are [-10, 15] and [20, 0] respectively. Tuning parameters are set to $k=1$, $\Gamma =I_3$ (identity matrix), and $\alpha =1000$.\relax }}{44}{figure.caption.34}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Simple UAV dynamics visual servoing Simulink simulation. The blue square is flying UAV at constant altitude and the red square is a target on the ground moving at $-5m/s$. The initial UAV and target positions are [10, 15] and [-10, 0] respectively. Tuning parameters are set to $k=1$, $\Gamma =I_3$ (identity matrix), and $\alpha =1000$.\relax }}{45}{figure.caption.35}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Control system diagram for the inertial line of sight vector backstepping controller. In this configuration, the backstepping controller needs the positions of multirotor and target.\relax }}{51}{figure.caption.36}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Control system diagram for the image-based backstepping controller. Note that the backstepping controller only requires the image coordinates of the target.\relax }}{51}{figure.caption.37}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Simulation result for the backstepping control using the inertial LOS vector. The ground target is static ($0m/s$). The initial UAV and target positions are [-140, 0, -90] and [0, 0, 0] respectively. Tuning parameters are set to $k=0.12$, $k_1=1$, $k_2=1$, $k_3=1$, and $\Gamma =0.01*I_3$ (identity matrix).\relax }}{52}{figure.caption.38}
\contentsline {figure}{\numberline {4.9}{\ignorespaces Simulation result for the backstepping control using the inertial LOS vector. The ground target is moving at the speed of $5m/s$. The initial UAV and target positions are [-110, 0, -90] and [0, 0, 0] respectively. Tuning parameters are set to $k=0.12$, $k_1=1$, $k_2=1$, $k_3=1$, and $\Gamma =0.01*I_3$ (identity matrix). In this case, the target is not placed at the center of image because the horizontal error is computed in the vehicle-1 frame meaning that the pitch of multirotor is not compensated.\relax }}{53}{figure.caption.39}
\contentsline {figure}{\numberline {4.10}{\ignorespaces Simulation result for the backstepping control using the inertial LOS vector. The ground target is moving at the speed of $-5m/s$. The initial UAV and target positions are [-110, 0, -90] and [0, 0, 0] respectively. Tuning parameters are set to $k=0.12$, $k_1=1$, $k_2=1$, $k_3=1$, and $\Gamma =0.01*I_3$ (identity matrix). In this case, the target is not placed at the center of image because the horizontal error is computed in the vehicle-1 frame meaning that the pitch of multirotor is not compensated.\relax }}{54}{figure.caption.40}
\contentsline {figure}{\numberline {4.11}{\ignorespaces Simulation result for the backstepping control using the normalized target pixel coordinates. The ground target is static ($0m/s$). The initial UAV and target positions are [-140, 0, -90] and [0, 0, 0] respectively. Tuning parameters are set to $k=0.12$, $k_1=1$, $k_2=1$, $k_3=1$, and $\Gamma =0.01*I_3$ (identity matrix).\relax }}{56}{figure.caption.41}
\contentsline {figure}{\numberline {4.12}{\ignorespaces Simulation result for the backstepping control using the normalized target pixel coordinates. The ground target is moving at the speed of $5m/s$. The initial UAV and target positions are [-110, 0, -90] and [0, 0, 0] respectively. Tuning parameters are set to $k=0.12$, $k_1=1$, $k_2=1$, $k_3=1$, and $\Gamma =0.01*I_3$ (identity matrix). In this case, the target is not placed at the center of image because the horizontal error is computed in the vehicle-1 frame meaning that the pitch of multirotor is not compensated.\relax }}{57}{figure.caption.42}
\contentsline {figure}{\numberline {4.13}{\ignorespaces Simulation result for the backstepping control using the normalized target pixel coordinates. The ground target is moving at the speed of $-5m/s$. The initial UAV and target positions are [-110, 0, -90] and [0, 0, 0] respectively. Tuning parameters are set to $k=0.12$, $k_1=1$, $k_2=1$, $k_3=1$, and $\Gamma =0.01*I_3$ (identity matrix). In this case, the target is not placed at the center of image because the horizontal error is computed in the vehicle-1 frame meaning that the pitch of multirotor is not compensated.\relax }}{58}{figure.caption.43}
\addvspace {10\p@ }
